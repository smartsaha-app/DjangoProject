import httpx
import os
from django.conf import settings

from SmartSaha.services.context_builder import ContextBuilder

BASE_PROMPT = """
Tu es un ingenieur agronome expert √† Madagascar.
Reponds toujours de maniere pr√©cise, pratique, court et adaptee aux conditions locales :
- Inclue les saisons, sols et pratiques agricoles typiques.
- Ne donne jamais de reponses vagues.
- si cest un estimation, calcule avec les donnees qu on te fourni et tes connaissances
- Si tu ne sais pas, indique clairement que l‚Äôinformation n‚Äôest pas disponible.
"""
class DeepSeekClient:
    def __init__(self, model="deepseek/deepseek-r1:free"):
        self.api_key = getattr(settings, "OPENROUTER_API_KEY", None) or os.getenv("OPENROUTER_API_KEY")
        if not self.api_key:
            raise ValueError("OPENROUTER_API_KEY manquant dans settings ou .env")

        self.base_url = "https://openrouter.ai/api/v1"
        self.model = model

    def ask(self, question: str, parcel_uuid: str = None, user_modules: dict = None):
        context_data = ContextBuilder.build_context(parcel_uuid, user_modules)
        print(context_data)
        full_prompt = f"{BASE_PROMPT}\n\nDonn√©es locales:\n{context_data}\n\nQuestion: {question}\nR√©ponse:"
        print(full_prompt)
        print("OPENROUTER_API_KEY =", self.api_key)

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": full_prompt}]
        }

        with httpx.Client(timeout=60.0) as client:
            try:
                response = client.post(f"{self.base_url}/chat/completions", json=payload, headers=headers)
                print("Status:", response.status_code)
                print("Response:", response.text[:500])  # debug rapide
                response.raise_for_status()
                data = response.json()
            except httpx.HTTPStatusError as e:
                return f"Erreur API OpenRouter ({e.response.status_code}): {e.response.text}"
            except Exception as e:
                return f"Erreur interne: {str(e)}"

        # Retourne le contenu de la r√©ponse
        try:
            return data["choices"][0]["message"]["content"]
        except (KeyError, IndexError):
            return "Aucune r√©ponse re√ßue du mod√®le."


import os
from django.conf import settings
from google import genai

from SmartSaha.services.context_builder import ContextBuilder


class GeminiClient:
    def __init__(self, model="google/gemini-2.0-flash-exp:free"):
        self.api_key = getattr(settings, "GEMINI_API_KEY", None) or os.getenv("GEMINI_API_KEY")
        if not self.api_key:
            raise ValueError("GEMINI_API_KEY manquant dans settings ou .env")

        self.model = model
        self.client = genai.Client(api_key=self.api_key)

    def ask(self, question: str, parcel_uuid: str = None, user_modules: dict = None):
        context_data = ContextBuilder.build_context(parcel_uuid, user_modules)
        print(context_data)

        full_prompt = f"{BASE_PROMPT}\n\nDonn√©es locales:\n{context_data}\n\nQuestion: {question}\nR√©ponse:"
        print(full_prompt)
        print("GEMINI_API_KEY =", self.api_key[:10] + "...")  # S√©curit√© : n'affiche pas toute la cl√©

        try:
            response = self.client.models.generate_content(
                model=self.model,
                contents=full_prompt
            )
            print("R√©ponse Gemini re√ßue")
            return response.text

        except Exception as e:
            return f"Erreur API Gemini: {str(e)}"

class WorkingAIClient:
    def __init__(self):
        # Liste de mod√®les gratuits qui marchent sur OpenRouter
        self.models = [
            "anthropic/claude-3-haiku:free",  # ü•á Premier choix
            "google/gemini-2.0-flash-exp:free",  # ü•à Deuxi√®me choix
            "meta-llama/llama-3.1-8b-instruct:free",  # ü•â Troisi√®me choix
            "microsoft/wizardlm-2-8x22b:free"  # üí™ Backup
        ]

    def ask(self, question, parcel_uuid=None, user_modules=None):
        # 1. R√©cup√®re le contexte (comme avant)
        context_data = ContextBuilder.build_context(parcel_uuid, user_modules)
        full_prompt = f"{BASE_PROMPT}\n\nDonn√©es locales:\n{context_data}\n\nQuestion: {question}\nR√©ponse:"

        # 2. Essaie chaque mod√®le jusqu'√† ce qu'un marche
        for model in self.models:
            try:
                print(f"üîÑ Essai avec le mod√®le: {model}")

                headers = {
                    "Authorization": f"Bearer {getattr(settings, "OPENROUTER_API_KEY", None) or os.getenv("OPENROUTER_API_KEY")}",
                    "Content-Type": "application/json"
                }
                payload = {
                    "model": model,
                    "messages": [{"role": "user", "content": full_prompt}]
                }

                # 3. Appel API
                with httpx.Client(timeout=60.0) as client:
                    response = client.post(
                        "https://openrouter.ai/api/v1/chat/completions",
                        json=payload,
                        headers=headers
                    )

                    if response.status_code == 200:
                        data = response.json()
                        print(f"‚úÖ Succ√®s avec {model}")
                        return data["choices"][0]["message"]["content"]
                    else:
                        print(f"‚ùå {model} a √©chou√©: {response.status_code}")
                        continue

            except Exception as e:
                print(f"‚ùå Erreur avec {model}: {e}")
                continue

        # 4. Si tout √©choue
        return "D√©sol√©, tous les services IA sont temporairement satur√©s. R√©essaie dans 1-2 minutes."


class MistralRAGClient:
    def __init__(self, model="mistral-medium"):
        self.api_key = getattr(settings, "MISTRAL_API_KEY", None) or os.getenv("MISTRAL_API_KEY")
        if not self.api_key:
            raise ValueError("MISTRAL_API_KEY manquant dans settings ou .env")

        self.model = model
        try:
            from mistralai import Mistral
            self.mistral_available = True
        except ImportError:
            self.mistral_available = False

    def ask(self, question: str, parcel_uuid: str = None, user_modules: dict = None):
        """Version RAG avec contexte local"""
        if not self.mistral_available:
            return "Erreur: Package 'mistralai' non install√©. Ex√©cutez: pip install mistralai"

        # Construction du contexte RAG
        context_data = ContextBuilder.build_context(parcel_uuid, user_modules)
        print("Contexte RAG:", context_data)

        # Prompt RAG complet
        full_prompt = f"""
{BASE_PROMPT}

CONTEXTE LOCAL ET DONN√âES UTILISATEUR:
{context_data}

QUESTION √Ä R√âSOUDRE:
{question}

BAS√â SUR LE CONTEXTE CI-DESSUS, R√âPONDS DE MANI√àRE PR√âCISE ET ADAPT√âE :
"""
        print("Prompt Mistral RAG g√©n√©r√©")
        print("MISTRAL_API_KEY =", self.api_key[:10] + "...")

        try:
            from mistralai import Mistral

            with Mistral(api_key=self.api_key) as client:
                response = client.chat.complete(
                    model=self.model,
                    messages=[
                        {
                            "role": "system",
                            "content": "Tu es Dr. Andry Rakoto, expert agronome malgache. R√©ponses courtes, pr√©cises, bas√©es sur les donn√©es fournies."
                        },
                        {
                            "role": "user",
                            "content": full_prompt
                        }
                    ],
                    temperature=0.3,  # R√©ponses pr√©cises
                    max_tokens=1000,
                    stream=False
                )

            print("R√©ponse Mistral RAG re√ßue")
            return response.choices[0].message.content

        except Exception as e:
            error_msg = f"Erreur API Mistral: {str(e)}"
            print(f"‚ùå {error_msg}")
            return error_msg